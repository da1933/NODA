{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/carolineroper/Documents/School/Machine Learning/Reset_Project/noda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import project_env as pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bring in BOFI_NBR, SCREENING_DISP_CODE\n",
    "data_simple = pd.read_csv('data_processing/output/data_simple.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "data_simple = data_simple[['SCREENING_DISP_CODE','UNIQUE_ID','BOFI_NBR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCREENING_DISP_CODE</th>\n",
       "      <th>UNIQUE_ID</th>\n",
       "      <th>BOFI_NBR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>255544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>257683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>255696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>251021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>246712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCREENING_DISP_CODE  UNIQUE_ID BOFI_NBR\n",
       "0                  NaN          0   255544\n",
       "1                  NaN          1   257683\n",
       "2                  NaN          2   255696\n",
       "3                  NaN          3   251021\n",
       "4                  NaN          4   246712"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin_features: (269543, 2)\n",
      "num_features: (280294, 5)\n",
      "date_features: (272088, 21)\n",
      "cat_features: (280294, 8)\n",
      "rearrest: (269543, 2)\n"
     ]
    }
   ],
   "source": [
    "bin_features = pd.read_csv('data_processing/output/df_bin_features.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "num_features = pd.read_csv('data_processing/output/df_num_features.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "date_features = pd.read_csv('data_processing/output/df_date_features.csv', encoding = \"ISO-8859-1\", low_memory=False) \\\n",
    "                            .drop('JUVENILE_FLAG',axis=1)\n",
    "cat_features = pd.read_csv('data_processing/output/df_cat_features.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "rearrest = pd.read_csv('data_processing/output/df_rearrest_times.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "\n",
    "print('bin_features: %s' %(str(rearrest.shape)))\n",
    "print('num_features: %s' %(str(num_features.shape)))\n",
    "print('date_features: %s' %(str(date_features.shape)))\n",
    "print('cat_features: %s' %(str(cat_features.shape)))\n",
    "print('rearrest: %s' %(str(rearrest.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(rearrest, \\\n",
    "                 bin_features,\\\n",
    "                 on='UNIQUE_ID', \\\n",
    "                 how='left')\n",
    "merged = pd.merge(merged, \\\n",
    "                 num_features,\\\n",
    "                 on='UNIQUE_ID', \\\n",
    "                 how='left')\n",
    "merged = pd.merge(merged, \\\n",
    "                 date_features,\\\n",
    "                 on='UNIQUE_ID', \\\n",
    "                 how='left')\n",
    "merged = pd.merge(merged, \\\n",
    "                 cat_features,\\\n",
    "                 on='UNIQUE_ID', \\\n",
    "                 how='left')\n",
    "merged = pd.merge(merged, \\\n",
    "                 data_simple,\\\n",
    "                 on='UNIQUE_ID', \\\n",
    "                 how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged.to_csv('merged_pj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UNIQUE_ID', 'NEXT_ARREST_TIME', 'CRIMINAL_FLAG',\n",
       "       'FINAL_DETENTION_FLAG', 'HABITUAL_OFFENDER_FLAG',\n",
       "       'INITIAL_DETENTION_FLAG', 'JUVENILE_FLAG', 'SADA_SEX', 'SEX',\n",
       "       'TOT_NUM_DEF', 'MULTIPLE_DEF_FLAG', 'SCREENING_DAYS', 'POLICE_RPT_DAYS',\n",
       "       'POLICE_RPT_DATE', 'ARREST_DATE', 'DOB', 'SCREENING_DISP_DATE',\n",
       "       'BAR_ADMISSION', 'POLICE_RPT_DATE_y', 'ARREST_DATE_y', 'DOB_y',\n",
       "       'SCREENING_DISP_DATE_y', 'BAR_ADMISSION_y', 'POLICE_RPT_DATE_m',\n",
       "       'ARREST_DATE_m', 'DOB_m', 'SCREENING_DISP_DATE_m', 'BAR_ADMISSION_m',\n",
       "       'AGE', 'BAR_ADMIT_DAYS', 'ARREST_TO_SCREEN', 'AGE_NA',\n",
       "       'AGE_JUV_INVALID', 'ARREST_CREDIT_CODE', 'CHARGE_CLASS', 'CHARGE_TYPE',\n",
       "       'LEAD_CHARGE_CODE', 'PARTY', 'RACE', 'SADA_RACE', 'SCREENING_DISP_CODE',\n",
       "       'BOFI_NBR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['UNIQUE_ID', 'NEXT_ARREST_TIME', 'ARREST_DATE', 'ARREST_DATE_y','BOFI_NBR','SCREENING_DISP_CODE',\\\n",
    "        'BAR_ADMIT_DAYS','CRIMINAL_FLAG', \\\n",
    "        'FINAL_DETENTION_FLAG', 'HABITUAL_OFFENDER_FLAG', \\\n",
    "        'INITIAL_DETENTION_FLAG', 'JUVENILE_FLAG', 'SADA_SEX', \\\n",
    "        'SEX', 'TOT_NUM_DEF', 'MULTIPLE_DEF_FLAG', 'SCREENING_DAYS', \\\n",
    "        'SCREENING_DISP_DATE_y', \\\n",
    "        'SCREENING_DISP_DATE_m', 'AGE', 'ARREST_TO_SCREEN', \\\n",
    "        'CHARGE_CLASS', 'CHARGE_TYPE', 'PARTY', 'RACE', \\\n",
    "        'SADA_RACE','AGE_JUV_INVALID','AGE_NA']\n",
    "\n",
    "merged = merged[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged.to_csv('merged_pj.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#identify arrests where at least one charge was accepted\n",
    "accepted = merged[merged['SCREENING_DISP_CODE']==230][['BOFI_NBR','ARREST_DATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#identify arrests where at least one charge was accepted\n",
    "accepted = merged[merged['SCREENING_DISP_CODE']==230][['BOFI_NBR','ARREST_DATE']]\n",
    "\n",
    "#drop rows where at least one charge was accepted during that arrest\n",
    "classified = pd.merge(merged, \\\n",
    "                 accepted, \\\n",
    "                 on=['BOFI_NBR','ARREST_DATE'], \\\n",
    "                 how='outer',\\\n",
    "                 indicator = True)\n",
    "\n",
    "classified['ACCEPTED'] = np.where(classified['_merge']=='both', 1, 0)\n",
    "\n",
    "classified = classified.drop('_merge', axis=1)\n",
    "\n",
    "#remove duplicate arrests on same day\n",
    "#confirmed that it's possible that an arrest has at least one charge was accepted and is still flagged as \"delete\"\n",
    "classified = classified[classified['NEXT_ARREST_TIME']!='Delete']\n",
    "\n",
    "#convert NEXT_ARREST_TIME to numeric\n",
    "classified['NEXT_ARREST_TIME'] = classified['NEXT_ARREST_TIME'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.pivot_table(classified, index = ['NEXT_ARREST_TIME'], columns=['ACCEPTED'], aggfunc=lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_var = ['SADA_SEX', 'SEX', 'PARTY', 'RACE', 'SADA_RACE', \\\n",
    "           'SCREENING_DISP_DATE_y', 'SCREENING_DISP_DATE_m', 'CHARGE_TYPE', \\\n",
    "           'CHARGE_CLASS', 'ARREST_DATE_y']\n",
    "\n",
    "cat_var_df = pd.DataFrame()\n",
    "\n",
    "for column in cat_var:\n",
    "    category = np.repeat(classified.loc[:,column].name, len(classified.loc[:,column].value_counts(dropna=False)))\n",
    "    value = classified.loc[:,column].value_counts(dropna=False).index\n",
    "    count = classified.loc[:,column].value_counts(dropna=False)\n",
    "    cat_var_df = cat_var_df.append(pd.DataFrame(np.transpose(np.vstack([category, value, count]))))\n",
    "cat_var_df.columns = ['Category', 'Value', 'Count']\n",
    "cat_var_df['Count'] = pd.to_numeric(cat_var_df['Count'])\n",
    "\n",
    "cat_var_df.fillna(value = \"Missing\", inplace=True)\n",
    "\n",
    "cat_var_df['Label'] = cat_var_df['Category'] + '_' + cat_var_df['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data 25068\n",
      "(100272, 29)\n",
      "Val Data 20055\n",
      "Train Data 80217\n",
      "Test Data 21078\n",
      "(84308, 29)\n",
      "Val Data 16862\n",
      "Train Data 67446\n"
     ]
    }
   ],
   "source": [
    "#two rounds of splits so predicted judge training set includes all training records from risk prediction model and so on.\n",
    "\n",
    "test_ne_1, train_ne_1, val_ne_1 = pe.split_data(classified[classified['ACCEPTED']==0], test_split=.2, \\\n",
    "                                 train_split=.64, by_var='ARREST_DATE_y', random_state=1)\n",
    "\n",
    "test_ne_2, train_ne_2, val_ne_2 = pe.split_data(classified[classified['ACCEPTED']==1], test_split=.2, \\\n",
    "                                 train_split=.64, by_var='ARREST_DATE_y', random_state=1)\n",
    "\n",
    "test_ne = pd.concat([test_ne_1, test_ne_2],axis=0)\n",
    "train_ne = pd.concat([train_ne_1, train_ne_2],axis=0)\n",
    "val_ne = pd.concat([val_ne_1, val_ne_2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ne.to_csv('data_train_pj.csv', index=False)\n",
    "test_ne.to_csv('data_test_pj.csv', index=False)\n",
    "val_ne.to_csv('data_val_pj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_var_enc = pe.one_hot_encode(classified[cat_var])\n",
    "cat_var_enc = pd.DataFrame(cat_var_enc.toarray(), index=classified.index) #can pass the column names here - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "after_enc_df = pd.DataFrame()\n",
    "\n",
    "for column in list(cat_var_enc.columns):\n",
    "    after_enc_df = after_enc_df.append(pd.DataFrame([column,sum(cat_var_enc.loc[:,column])]).transpose())\n",
    "after_enc_df.columns = ['current_name', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code below creates meaningful column names for encoded variables - need to QA more thoroughly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_name_df = pd.merge(after_enc_df, cat_var_df, on='Count', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_name</th>\n",
       "      <th>Count</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18660.0</td>\n",
       "      <td>SADA_SEX</td>\n",
       "      <td>-1</td>\n",
       "      <td>SADA_SEX_-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18660.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y_1996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y_1986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y_1983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y_1986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y_1983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>33.0</td>\n",
       "      <td>18660.0</td>\n",
       "      <td>SADA_SEX</td>\n",
       "      <td>-1</td>\n",
       "      <td>SADA_SEX_-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>33.0</td>\n",
       "      <td>18660.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>SCREENING_DISP_DATE_y_1996.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    current_name    Count               Category   Value  \\\n",
       "0            0.0  18660.0               SADA_SEX      -1   \n",
       "1            0.0  18660.0  SCREENING_DISP_DATE_y  1996.0   \n",
       "23          22.0      1.0  SCREENING_DISP_DATE_y  1986.0   \n",
       "24          22.0      1.0  SCREENING_DISP_DATE_y  1983.0   \n",
       "25          23.0      1.0  SCREENING_DISP_DATE_y  1986.0   \n",
       "26          23.0      1.0  SCREENING_DISP_DATE_y  1983.0   \n",
       "36          33.0  18660.0               SADA_SEX      -1   \n",
       "37          33.0  18660.0  SCREENING_DISP_DATE_y  1996.0   \n",
       "\n",
       "                           Label  \n",
       "0                    SADA_SEX_-1  \n",
       "1   SCREENING_DISP_DATE_y_1996.0  \n",
       "23  SCREENING_DISP_DATE_y_1986.0  \n",
       "24  SCREENING_DISP_DATE_y_1983.0  \n",
       "25  SCREENING_DISP_DATE_y_1986.0  \n",
       "26  SCREENING_DISP_DATE_y_1983.0  \n",
       "36                   SADA_SEX_-1  \n",
       "37  SCREENING_DISP_DATE_y_1996.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = col_name_df.current_name.value_counts() \n",
    "\n",
    "col_name_df[col_name_df.current_name.isin(list(s[s > 1].index))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#these row indexes found manually - not sure how to do this more automatically\n",
    "\n",
    "col_name_df = col_name_df.drop([1, 23, 26, 36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_name_df['current_name'] = pd.to_numeric(col_name_df['current_name'])\n",
    "\n",
    "col_name_df.index = col_name_df['current_name']\n",
    "\n",
    "col_dict = col_name_df['Label'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classified_enc = classified.drop(cat_var[:-1], axis=1)\n",
    "classified_enc = pd.merge(classified_enc, \\\n",
    "                       cat_var_enc,\\\n",
    "                       left_index=True, \\\n",
    "                       right_index=True, \\\n",
    "                       how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classified_enc = classified_enc.rename(columns = col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data 25068\n",
      "(100272, 93)\n",
      "Val Data 20055\n",
      "Train Data 80217\n",
      "Test Data 21078\n",
      "(84308, 93)\n",
      "Val Data 16862\n",
      "Train Data 67446\n"
     ]
    }
   ],
   "source": [
    "#two rounds of splits so predicted judge training set includes all training records from risk prediction model and so on.\n",
    "\n",
    "test_1, train_1, val_1 = pe.split_data(classified_enc[classified_enc['ACCEPTED']==0], test_split=.2, \\\n",
    "                                 train_split=.64, by_var='ARREST_DATE_y', random_state=1)\n",
    "\n",
    "test_2, train_2, val_2 = pe.split_data(classified_enc[classified_enc['ACCEPTED']==1], test_split=.2, \\\n",
    "                                 train_split=.64, by_var='ARREST_DATE_y', random_state=1)\n",
    "\n",
    "test = pd.concat([test_1, test_2],axis=0)\n",
    "train = pd.concat([train_1, train_2],axis=0)\n",
    "val = pd.concat([val_1, val_2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.to_csv('train_pj.csv',index=False)\n",
    "val.to_csv('val_pj.csv',index=False)\n",
    "test.to_csv('test_pj.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
